# âš¡ Spark Local Cluster (tipo Databricks) con Docker + Jupyter + `.env`

**Â¿Para quÃ© sirve?**  

Levanta en tu mÃ¡quina un _mini-Databricks_ totalmente **offline** para:  Probar notebooks y ETLs PySpark localmente â€¢ Reproducir cargas distribuidas sin coste â€¢ EnseÃ±ar Spark sin depender de la nube

---

## ğŸš€ Â¿QuÃ© incluye?
| Componente | FunciÃ³n |
|------------|---------|
| `spark-master` | Nodo coordinador Spark |
| `spark-worker` | RÃ©plicas configurables |
| `jupyter` | Notebook conectado al cluster |
| `run.sh` | Build + up + ejecuciÃ³n de jobs |
| `.env` | â€œCluster specâ€ al estilo Databricks |

---

## ğŸ“‚ Ãrbol del proyecto

```plaintext
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ run.sh
â””â”€â”€ spark/
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ entrypoint.sh
    â”œâ”€â”€ spark-defaults.conf
    â””â”€â”€ jobs/
        â””â”€â”€ ejemplo.py
```

---

## ğŸ› ï¸ Requisitos
* Docker + Docker Compose  
* Linux/macOS/WSL2  
* Python â‰¥3.8 (solo si quieres aÃ±adir scripts nuevos)

---

## âš™ï¸ ConfiguraciÃ³n rÃ¡pida (`.env`)
```env
# Workers
SPARK_WORKER_INSTANCES=2
SPARK_WORKER_MEMORY=8g
SPARK_WORKER_CORES=4

# Driver
SPARK_DRIVER_MEMORY=4g

# Ejecutores
SPARK_EXECUTOR_INSTANCES=4
SPARK_EXECUTOR_MEMORY=4g
SPARK_EXECUTOR_CORES=2

# Finos
SPARK_NETWORK_TIMEOUT=120s
SPARK_TASK_MAX_FAILURES=4
SPARK_DEFAULT_PARALLELISM=8

# Event-log desactivado (evita Kerberos)
SPARK_EVENT_LOG_ENABLED=false

# Deploy mode
SPARK_DEPLOY_MODE=client
```

â¸»

â–¶ï¸ Uso bÃ¡sico

chmod +x run.sh        # 1) dar permisos la primera vez
./run.sh               # 2) levantar cluster + ejemplo.py
./run.sh mi_job.py     # 3) lanzar otro script en spark/jobs/


â¸»

ğŸ”„ Reiniciar o limpiar el cluster
```
# Apagar y eliminar volÃºmenes
docker compose down -v

# (Opcional) limpiar cache de imÃ¡genes buildkit
docker builder prune -af

# Volver a levantar todo
./run.sh
```

â¸»

ğŸŒ Interfaces Ãºtiles
- Spark UI â†’ http://localhost:8080
- Jupyter  â†’ http://localhost:8888

â¸»

ğŸ§ª Script de ejemplo (spark/jobs/ejemplo.py)

```python
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("EjemploDocker").getOrCreate()
df = spark.range(1_000_000).withColumnRenamed("id", "numero")
df.selectExpr("numero", "numero * 2 AS doble").show(10)
spark.stop()
```

â¸»

ğŸ“‹ Ver logs de los contenedores

# Spark Master
docker logs spark-master

# Primer Worker
docker logs sparks-cluster-spark-worker-1

# Jupyter
docker logs spark-jupyter

# Seguir logs en tiempo real
docker logs -f spark-master


â¸»

ğŸ—ï¸ Detalles internos

- Ivy fix â†’ /opt/bitnami/.ivy2 es el repo Maven local; sin acceso a /root.

- Event-log off (spark.eventLog.enabled=false) â†’ no requiere Kerberos.

- Usuario seguro â†’ Contenedor corre como uid 1001 (HOME=/opt/bitnami).

- ParÃ¡metros dinÃ¡micos â†’ Memorias/nÃºcleos vienen de .env vÃ­a run.sh --conf.

â¸»

âœ… Ventajas
- Cero cloud Â· Reproducible Â· Extensible Â· Perfecto para docencia y POC.

â¸»

ğŸ“œ Licencia

MIT â€“ Ãšsalo, modifÃ­calo y compÃ¡rtelo.
